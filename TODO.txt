COMPLETED:

1. Create detection pipeline by integrating MobileNetv2-SSD code
2. Implement CAM mode for online tracking
3. Evaluation on MOT16:
    a. Generate pre-computed bboxes + detections using SSD
    b. Generate tracking results for MOT16 training data with EVAL mode using both default and SSD detections separately
    c. Use Py-MOT-metrics library to generate a set of metrics for each case - Benchmark results saved in ./Results/Task-1/benchmark_results.txt
4. Extend the code to track vehicles in a given video file
5. Evaluation on UA-DETRAC:
    a. Generate detections using given DPM bboxes, and pre-computed bboxes + detections using SSD



-----------------------------

LINGERING DOUBTS:

1. How reliable are the MOT16 benchmark results of Task-1? To clear this, complete evaluation of the MOT16 set (training + test) needs to be done with MISC.TODO #1 to reproduce originial DeepSORT paper results.


-----------------------------

TODO:

1. Benchmark the vehicle tracker on the dataset (only the first 20 sequences of training set) for the default DPM, default R-CNN and custom SSD detections
    - Normalize the vehicle encodings, and then see if things improve (implemented, need to test it)
    - Modify generate_vehicle_detections code to take args, get all 3 sets of detections again

2. Perform sensitivity analysis for both human and vehicle tracking
    - Use commandline scripting -- need to modify the track_humans code to take args

3. Add SSD online detection mode for vehicles -- for measuring online operation FPS

-----------------------------

MISC. TODO:

1. DeepSORT paper benchmark results are computed using a different detector (from paper â€œPoi:Multiple object tracking with high performance detection and appearance feature"). Use this to reproduce the benchmark results and compare with my results.

